{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YesidORC/Proyecto_DL_2024_1/blob/main/02_PreprocesadoSiata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MLLzAbO5Flc_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfZsvIFFFldG"
      },
      "source": [
        "Se procede a realizar la partición en train/validation/test.\n",
        "Para este caso se procede de forma manual haciendo un 60% para train 20% para validation y 20% para test\n",
        "\n",
        "Se realizará un análisis univariado - unistep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "P-IweBJlFldK"
      },
      "outputs": [],
      "source": [
        "def train_val_test_split(serie, tr_size=0.6, vl_size=0.2, ts_size=0.2 ):\n",
        "    # Definir número de datos en cada subserie\n",
        "    N = serie.shape[0]\n",
        "    Ntrain = int(tr_size*N)  # Número de datos de entrenamiento\n",
        "    Nval = int(vl_size*N)    # Número de datos de validación\n",
        "    Ntst = N - Ntrain - Nval # Número de datos de prueba\n",
        "\n",
        "    # Realizar partición\n",
        "    train = serie[0:Ntrain]\n",
        "    val = serie[Ntrain:Ntrain+Nval]\n",
        "    test = serie[Ntrain+Nval:]\n",
        "\n",
        "    return train, val, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pPIXHV2QFldM"
      },
      "outputs": [],
      "source": [
        "def crear_dataset_supervisado(array, input_length, output_length):\n",
        "    X, Y = [], []    # Listados que contendrán los datos de entrada y salida del modelo\n",
        "    shape = array.shape\n",
        "    if len(shape)==1: # Si tenemos sólo una serie (univariado)\n",
        "        fils, cols = array.shape[0], 1\n",
        "        array = array.reshape(fils,cols)\n",
        "    else: # Multivariado\n",
        "        fils, cols = array.shape\n",
        "\n",
        "    # Generar los arreglos\n",
        "    for i in range(fils-input_length-output_length):\n",
        "        X.append(array[i:i+input_length,0:cols])\n",
        "        Y.append(array[i+input_length:i+input_length+output_length,-1].reshape(output_length,1))\n",
        "\n",
        "    # Convertir listas a arreglos de NumPy\n",
        "    X = np.array(X)\n",
        "    Y = np.array(Y)\n",
        "\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url=\"/content/drive\"\n",
        "drive.mount(url)\n",
        "file_path=\"/content/drive/MyDrive/Colab Notebooks/Proyecto_Final_DL\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UiZh25QGW9Z",
        "outputId": "80b52cea-9209-4f72-f784-089a344c3283"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AA0Sg-naFldN"
      },
      "outputs": [],
      "source": [
        "df= pd.read_csv(file_path+\"/TemperaturaEst202_2013_2022.csv\",index_col=0)\n",
        "df.index = pd.to_datetime(df.index)\n",
        "df.interpolate(method='time',inplace=True)\n",
        "tr, vl, ts = train_val_test_split(df['Temperatura'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDj9ANfBG0Q0",
        "outputId": "51e7b9b2-b2b3-4ac9-c6bf-0be360cb092a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Temperatura    0\n",
              "Calidad        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DNnr46xTFldO"
      },
      "outputs": [],
      "source": [
        "# Definición de los hiperparámetros INPUT_LENGTH y OUTPUT_LENGTH\n",
        "INPUT_LENGTH = 24    # Registros de 24 horas consecutivas a la entrada\n",
        "OUTPUT_LENGTH = 1    # El modelo va a predecir 1 hora a futuro\n",
        "\n",
        "# Datasets supervisados para entrenamiento (x_tr, y_tr), validación\n",
        "# (x_vl, y_vl) y prueba (x_ts, y_ts)\n",
        "x_tr, y_tr = crear_dataset_supervisado(tr.values, INPUT_LENGTH, OUTPUT_LENGTH)\n",
        "x_vl, y_vl = crear_dataset_supervisado(vl.values, INPUT_LENGTH, OUTPUT_LENGTH)\n",
        "x_ts, y_ts = crear_dataset_supervisado(ts.values, INPUT_LENGTH, OUTPUT_LENGTH)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(file_path+\"/x_tr.npy\",x_tr)\n",
        "np.save(file_path+\"/y_tr.npy\",y_tr)\n",
        "np.save(file_path+\"/x_vl.npy\",x_vl)\n",
        "np.save(file_path+\"/y_vl.npy\",y_vl)\n",
        "np.save(file_path+\"/x_ts.npy\",x_ts)\n",
        "np.save(file_path+\"/y_ts.npy\",y_ts)"
      ],
      "metadata": {
        "id": "FcBtMftGNjpA"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBICG9PSFldP",
        "outputId": "8370f61d-7f47-4c25-9bd4-e23fabe29989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaños entrada (BATCHES x INPUT_LENGTH x FEATURES) y de salida (BATCHES x OUTPUT_LENGTH x FEATURES)\n",
            "Set de entrenamiento - x_tr: (52563, 24, 1), y_tr: (52563, 1, 1)\n",
            "Set de validación - x_vl: (17504, 24, 1), y_vl: (17504, 1, 1)\n",
            "Set de prueba - x_ts: (17506, 24, 1), y_ts: (17506, 1, 1)\n"
          ]
        }
      ],
      "source": [
        "print('Tamaños entrada (BATCHES x INPUT_LENGTH x FEATURES) y de salida (BATCHES x OUTPUT_LENGTH x FEATURES)')\n",
        "print(f'Set de entrenamiento - x_tr: {x_tr.shape}, y_tr: {y_tr.shape}')\n",
        "print(f'Set de validación - x_vl: {x_vl.shape}, y_vl: {y_vl.shape}')\n",
        "print(f'Set de prueba - x_ts: {x_ts.shape}, y_ts: {y_ts.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Pcx1ob8GFldR"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def escalar_dataset(data_input):\n",
        "    NFEATS = data_input['x_tr'].shape[2]\n",
        "\n",
        "    # Generar listado con \"scalers\"\n",
        "    scalers = [MinMaxScaler(feature_range=(-1,1)) for i in range(NFEATS)]\n",
        "\n",
        "    # Arreglos que contendrán los datasets escalados\n",
        "    x_tr_s = np.zeros(data_input['x_tr'].shape)\n",
        "    x_vl_s = np.zeros(data_input['x_vl'].shape)\n",
        "    x_ts_s = np.zeros(data_input['x_ts'].shape)\n",
        "    y_tr_s = np.zeros(data_input['y_tr'].shape)\n",
        "    y_vl_s = np.zeros(data_input['y_vl'].shape)\n",
        "    y_ts_s = np.zeros(data_input['y_ts'].shape)\n",
        "\n",
        "    # Escalamiento: se usarán los min/max del set de entrenamiento para\n",
        "    # escalar la totalidad de los datasets\n",
        "\n",
        "    # Escalamiento Xs\n",
        "    for i in range(NFEATS):\n",
        "        x_tr_s[:,:,i] = scalers[i].fit_transform(x_tr[:,:,i])\n",
        "        x_vl_s[:,:,i] = scalers[i].transform(x_vl[:,:,i])\n",
        "        x_ts_s[:,:,i] = scalers[i].transform(x_ts[:,:,i])\n",
        "\n",
        "    # Escalamiento Ys\n",
        "    y_tr_s[:,:,0] = scalers[-1].fit_transform(y_tr[:,:,0])\n",
        "    y_vl_s[:,:,0] = scalers[-1].transform(y_vl[:,:,0])\n",
        "    y_ts_s[:,:,0] = scalers[-1].transform(y_ts[:,:,0])\n",
        "\n",
        "    # Conformar ` de salida\n",
        "    data_scaled = {\n",
        "        'x_tr_s': x_tr_s, 'y_tr_s': y_tr_s,\n",
        "        'x_vl_s': x_vl_s, 'y_vl_s': y_vl_s,\n",
        "        'x_ts_s': x_ts_s, 'y_ts_s': y_ts_s,\n",
        "    }\n",
        "\n",
        "    return data_scaled, scalers[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WgYQ5EbhFldS"
      },
      "outputs": [],
      "source": [
        "data_in = {\n",
        "    'x_tr': x_tr, 'y_tr': y_tr,\n",
        "    'x_vl': x_vl, 'y_vl': y_vl,\n",
        "    'x_ts': x_ts, 'y_ts': y_ts,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BwRynn8OFldT"
      },
      "outputs": [],
      "source": [
        "data_s, scaler = escalar_dataset(data_in)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8r-fFDzxFldU"
      },
      "outputs": [],
      "source": [
        "x_tr_s, y_tr_s = data_s['x_tr_s'], data_s['y_tr_s']\n",
        "x_vl_s, y_vl_s = data_s['x_vl_s'], data_s['y_vl_s']\n",
        "x_ts_s, y_ts_s = data_s['x_ts_s'], data_s['y_ts_s']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "P-GA78o6FldV"
      },
      "outputs": [],
      "source": [
        "np.save(file_path+\"/x_tr_s.npy\",x_tr_s)\n",
        "np.save(file_path+\"/y_tr_s.npy\",y_tr_s)\n",
        "np.save(file_path+\"/x_vl_s.npy\",x_vl_s)\n",
        "np.save(file_path+\"/y_vl_s.npy\",y_vl_s)\n",
        "np.save(file_path+\"/x_ts_s.npy\",x_ts_s)\n",
        "np.save(file_path+\"/y_ts_s.npy\",y_ts_s)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}